# ğŸ” Desafio TÃ©cnico Ligia 2026 â€” ClassificaÃ§Ã£o de DesinformaÃ§Ã£o Digital (NLP)

Este repositÃ³rio contÃ©m a soluÃ§Ã£o completa para o desafio de **detecÃ§Ã£o de Fake News** da Liga AcadÃªmica de IA (LIGIA/UFPE) 2026, utilizando tÃ©cnicas de NLP, Engenharia de Features EstilÃ­sticas e SVM Linear calibrado.

## ğŸ“Š Resultados

| MÃ©trica | Valor (CV 5-Fold) |
|---|---|
| **F1-Score** | **0.99807** |
| Accuracy | 0.99904 |
| Precision | 0.99854 |
| Recall | 0.99762 |
| ROC AUC | 0.99998 |

- **Robustez:** F1 estÃ¡vel em 5 seeds distintas (amplitude = 0.00053)
- **Threshold otimizado:** 0.335 (tuning sem data leakage)

## ğŸ“‚ Estrutura do Projeto

```
LIGIA_FINAL/
â”œâ”€â”€ inputs/                      # Datasets originais
â”‚   â”œâ”€â”€ train.csv                # Dados de treino (22.844 artigos)
â”‚   â””â”€â”€ test.csv                 # Dados de teste (5.712 artigos)
â”œâ”€â”€ notebooks/                   # Pipeline sequencial
â”‚   â”œâ”€â”€ notebook_00_EDA.ipynb            # 1. AnÃ¡lise ExploratÃ³ria
â”‚   â”œâ”€â”€ notebook_01_preprocessing.ipynb  # 2. PrÃ©-processamento e Feature Engineering
â”‚   â”œâ”€â”€ notebook_02_modeling.ipynb       # 3. Modelagem, CV, SHAP e SubmissÃ£o
â”‚   â””â”€â”€ notebook_03_inference.ipynb      # 4. InferÃªncia e AnÃ¡lise de Erros
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ artifacts/               # Modelos e artefatos salvos
â”‚   â”‚   â”œâ”€â”€ best_model.pkl       # LinearSVC + CalibratedClassifierCV (modelo final)
â”‚   â”‚   â”œâ”€â”€ best_model_v2.pkl    # VersÃ£o alternativa do modelo (experimentaÃ§Ã£o)
â”‚   â”‚   â”œâ”€â”€ best_threshold.pkl   # Limiar otimizado
â”‚   â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl # Vetorizador TF-IDF fitado no treino
â”‚   â”‚   â”œâ”€â”€ style_scaler.pkl     # MaxAbsScaler para features de estilo
â”‚   â”‚   â”œâ”€â”€ subject_encoder.pkl  # LabelEncoder para a coluna 'subject'
â”‚   â”‚   â”œâ”€â”€ X_train.npz / X_test.npz  # Matrizes esparsas (TF-IDF + features de estilo)
â”‚   â”‚   â””â”€â”€ *.csv               # Datasets intermediÃ¡rios
â”‚   â””â”€â”€ figures/                 # GrÃ¡ficos de avaliaÃ§Ã£o e interpretabilidade
â”‚       â”œâ”€â”€ shap_bar.png         # SHAP feature importance
â”‚       â”œâ”€â”€ shap_summary.png     # SHAP summary plot
â”‚       â”œâ”€â”€ confusion_matrix.png # Matriz de confusÃ£o no holdout
â”‚       â””â”€â”€ ...                  # Curvas de calibraÃ§Ã£o, learning curve e distribuiÃ§Ãµes
â”œâ”€â”€ report/                      # Arquivos do relatÃ³rio tÃ©cnico-cientÃ­fico (IEEE)
â”œâ”€â”€ src/                         # MÃ³dulos refatorados para execuÃ§Ã£o reaproveitÃ¡vel
â”‚   â”œâ”€â”€ constants.py             # Constantes, metadados e diretÃ³rios do projeto
â”‚   â””â”€â”€ preprocessing.py         # FunÃ§Ãµes modulares de limpeza e feature engineering 
â”œâ”€â”€ artigo_ieee_final.pdf        # Artigo tÃ©cnico gerado em PDF pronto para avaliaÃ§Ã£o
â”œâ”€â”€ submission.csv               # Arquivo de submissÃ£o Kaggle
â”œâ”€â”€ requirements.txt             # DependÃªncias com versÃµes fixas
â””â”€â”€ README.md                    # Este arquivo
```

## ğŸ§  Metodologia

### Pipeline
A pipeline conta com reaproveitamento de cÃ³digo e orquestraÃ§Ã£o baseada no mÃ³dulo `src/` (`preprocessing.py` e `constants.py`) para modularidade e reprodutibilidade:
1. **RemoÃ§Ã£o de Data Leakage:** Tags de agÃªncia (Reuters, AP, AFP), URLs, bylines
2. **Feature Engineering EstilÃ­stico (15 features):** `caps_ratio`, `exclamation_count`, `word_count`, `avg_word_len`, `sentence_count`, `avg_sentence_len`, `question_count`, `quote_count`, `ellipsis_count`, `all_caps_words`, `title_caps_ratio`, `unique_word_ratio`, `sensational_count`, `title_len`, `text_len`
3. **PrÃ©-processamento de Texto:** LematizaÃ§Ã£o (NLTK WordNet + POS tagging), remoÃ§Ã£o de stopwords
4. **VetorizaÃ§Ã£o:** TF-IDF (unigramas, bigramas e trigramas, max 12.000 features)
5. **Modelo:** `LinearSVC(C=1.0, class_weight='balanced')` + `CalibratedClassifierCV(method='sigmoid', cv=3)`
6. **Threshold Tuning:** OtimizaÃ§Ã£o do limiar de decisÃ£o em holdout separado

### Interpretabilidade
- **Coeficientes SVC:** Ranking direto dos termos mais discriminativos (Fake vs Real)
- **SHAP LinearExplainer:** ExplicaÃ§Ã£o global e local das decisÃµes do modelo

## ğŸš€ Como Executar (Reprodutibilidade)

### 1. Clonar o RepositÃ³rio
```bash
git clone <URL_DO_REPOSITÃ“RIO>
cd LIGIA_FINAL
```

### 2. ConfiguraÃ§Ã£o do Ambiente
```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente (Windows)
venv\Scripts\activate

# Ativar ambiente (Linux/Mac)
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 3. Dados
Coloque os arquivos `train.csv` e `test.csv` da competiÃ§Ã£o Kaggle na pasta `inputs/`.

### 4. ExecuÃ§Ã£o dos Notebooks (em ordem)

```bash
jupyter notebook
```

Execute os notebooks **sequencialmente**:

| Ordem | Notebook | DescriÃ§Ã£o | SaÃ­das |
|---|---|---|---|
| 1 | `notebook_00_EDA.ipynb` | AnÃ¡lise ExploratÃ³ria: distribuiÃ§Ã£o de classes, features estilÃ­sticas, correlaÃ§Ãµes | GrÃ¡ficos em `outputs/figures/` |
| 2 | `notebook_01_preprocessing.ipynb` | Limpeza, feature engineering, TF-IDF, salvamento de artefatos | `X_train.npz`, `X_test.npz`, `tfidf_vectorizer.pkl`, `style_scaler.pkl` |
| 3 | `notebook_02_modeling.ipynb` | Treinamento, CV, threshold tuning, SHAP, geraÃ§Ã£o da submissÃ£o | `best_model.pkl`, `best_threshold.pkl`, `submission.csv` |
| 4 | `notebook_03_inference.ipynb` | InferÃªncia em novos artigos, anÃ¡lise de erros, validaÃ§Ã£o de coerÃªncia | AnÃ¡lises de confianÃ§a e zona de incerteza |

### 5. SubmissÃ£o
ApÃ³s executar o notebook 02 ou 03, o arquivo `submission.csv` serÃ¡ gerado na raiz do projeto, pronto para upload no Kaggle.

## ğŸ“¦ Tecnologias
- Python 3.x
- scikit-learn (LinearSVC, CalibratedClassifierCV, TF-IDF)
- NLTK (lematizaÃ§Ã£o, stopwords, POS tagging)
- SHAP (interpretabilidade)
- pandas, numpy, matplotlib, seaborn
